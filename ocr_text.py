# -*- coding: utf-8 -*-
"""OCR Text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ayfylg_LHSflSAOlf6VYQoFU8RszTIo1

# The below code does the following:
1. Reads through all files one by one, looking for occurrences of float numbers.

2. Looks for parameter names in the starting index of every line cross referenced by data from 'X1.json', and if found, appends that line to the data

3. To look for latest data for a parameter: it considers the last value in the string as the latest parameter. This is an implicit assumption I am making because dates appear to be arranged chronologically. Therefore by default, the last value will be the latest one.

4. Lastly, I have filtered data and added it to a dictionary as required.

5. Helper Functions I used:
  a) Time pattern matching
  b) Date pattern matching
  c) float detection
  d) file reading
  e) searching in json file for reading through X1.json

# Some things I have not been able to accomplish due to the shortage of time:


1. Correct for OCR errors - I had planned on utilising Levenshtein Distance to correct for OCR errors.

2. Unable to extract the 'unit' key for the dicitonary to non uniformity of unit values. A potential approach: A dictionary listing all kinds of units would have been helpful in extracting the unit keys.
"""

import re
from datetime import datetime

def convert_date_format(text):
    # Define the regex pattern to match dates in the format "30 Nov 18"
    date_pattern = r'(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{2})'

    # Find all matches of the date pattern in the text
    matches = re.findall(date_pattern, text)

    converted_dates = []
    for match in matches:
        # Convert the matched date into Python datetime format
        day, month, year = match
        date_str = f"{day} {month} {year}"
        converted_date = datetime.strptime(date_str, '%d %b %y').date()
        converted_dates.append(converted_date.strftime("%Y-%m-%d"))

    return converted_dates

import re
from datetime import datetime

def convert_time_format(text):

    new_text = str(text.split(" "))
    time_pattern = r'\b(2[0-3]|[01]?[0-9]):([0-5]?[0-9])\b'
    matches = re.findall(time_pattern, new_text)
    converted_times = []
    for match in matches:
        hour, minute = map(int, match)
        time_str = f"{hour}:{minute}"
        converted_time = datetime.strptime(time_str, '%H:%M').time()
        converted_times.append(converted_time.strftime("%H:%M"))

    return converted_times

def read_data_from_files(file_paths):
    all_data = ""  # Variable to store all data from files

    for file_path in file_paths:
        try:
            with open(file_path, 'r') as file:
                data = file.read()
                all_data += data + "\n"  # Append data from file to the variable
        except FileNotFoundError:
            print(f"File '{file_path}' not found. Skipping...")

    return all_data

def is_float(string):
    try:
        float(string)
        return True
    except ValueError:
        return False

def read_data_from_files(file_paths):
    all_data = ""  # Variable to store all data from files

    for file_path in file_paths:
        try:
            with open(file_path, 'r') as file:
                data = file.read()
                all_data += data + "\n"  # Append data from file to the variable
        except FileNotFoundError:
            print(f"File '{file_path}' not found. Skipping...")

    return all_data

file_paths = ["/content/02b832e1-66cc-4f35-8b52-abf41cd821b2.txt", "/content/0ab9800e-bc9a-4388-aaa2-d4fc05e7d111.txt", "/content/0b8706dc-c9af-4c6b-887d-2f85b5a511e7.txt","/content/0c59298d-4205-4f6a-8bc9-c078123da03a.txt","/content/0c848136-de54-49eb-a3c4-b04dda11ef42.txt","/content/0ca602c0-d93a-4ae2-b91f-532db7e174ae.txt","/content/0deee5f5-f9d3-4712-8d2e-c5f7cd9895dc.txt","/content/0ea75106-2a9d-4adc-9dad-33256e7d9aad.txt","/content/0ecb52fd-138f-4566-bdef-06fabdd7019d.txt"]  # Replace with actual file paths
all_data = read_data_from_files(file_paths)


import json

def search_in_json(file_path, search_string):
    # Load the JSON file
    with open(file_path, 'r') as file:
        data = json.load(file)

    # Iterate through the structure
    for item in data:
        if search_string == item["Abbreviation"]:
            return True
        if search_string in item["Synonyms"]:
            return True

    return False


flag = False
def filter_lines_with_same_occurrences(text):
    lines = text.strip().split('\n')
    considered_data = []
    num_occurrences = None
    index = 0
    for line in lines:
        flag = False;
        if "Request Number" in line:
            num_occurrences = sum(is_float(char) for char in line.split(" "))

        elif "Time Collected" in line:
            num_occurrences = sum(len(convert_time_format(char)) for char in line.split(" "))
        elif any(convert_date_format(char) != [] for char in line.split(" ")):
            for char in line.split(" "): print(convert_date_format(char))
            num_occurrences = sum(len(convert_date_format(char)) for char in line.split(" "))
        else:
            num_occurrences = sum(is_float(char) for char in line.split(" "))

        if num_occurrences is not None and num_occurrences!= 0 and sum(is_float(char) for char in line.split(" ")) == num_occurrences:
            index = 0
            for char in line.split(" "):
              if(not(search_in_json("X1.json", char))):
                  flag = flag + False
              else:
                if(index == 0):
                  flag = flag + True

              index +=1
            if(flag != False and flag!= 0):
              considered_data.append(line)
        elif num_occurrences is not None and num_occurrences!= 0 and sum(len(convert_time_format(char)) for char in line.split(" ")) == num_occurrences:
            index = 0
            for char in line.split(" "):
              if(not(search_in_json("X1.json", char))):
                  flag = flag + False
              else:
                if(index == 0):
                  flag = flag + True
            if(flag != False and flag!= 0):
                considered_data.append(line)
        elif num_occurrences is not None and num_occurrences!= 0 and sum(len(convert_date_format(char)) for char in line.split(" ")) == num_occurrences:
            index = 0
            for char in line.split(" "):
              if(not(search_in_json("X1.json", char))):
                  flag = flag + False
              else:
                if(index == 0):
                  flag = flag + True
            if(flag != False and flag!= 0):
              considered_data.append(line)



    return '\n'.join(considered_data)

considered_data = filter_lines_with_same_occurrences(all_data)

# Print the filtered data
print(considered_data)

def filter_data(line):
  new_line = ""
  dict1={}
  arr =[]
  latest_val_added = False
  for char in line.split(" "):

    if(search_in_json("X1.json", char)):

      new_line = new_line + 'parameter = ' + char
      dict1['parameter'] = char

    elif(is_float(char)) and not latest_val_added:
      for minichar in line.split(" "):
        if(is_float(minichar)):
          latest_val = minichar
      new_line = new_line + 'value = ' + latest_val
      dict1['value'] = latest_val
      latest_val_added = True

    else:
      a=0

  arr.append(dict1)
  return dict1
array1 = []
for line in considered_data.split('\n'):
  array1.append(filter_data(line))

print(array1)